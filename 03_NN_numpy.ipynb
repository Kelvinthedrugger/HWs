{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp nnsig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network using numpy\n",
    "#### works on cpu only if there's no pyopencl and else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fetch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fetch(url):\n",
    "    import requests, hashlib, os, tempfile\n",
    "    fp = os.path.join(tempfile.gettempdir(), hashlib.md5(url.encode('utf-8')).hexdigest())\n",
    "\n",
    "    if os.path.isfile(fp):\n",
    "        with open(fp, \"rb\") as f:\n",
    "            dat = f.read()\n",
    "    \n",
    "    else:\n",
    "        dat = requests.get(url).content\n",
    "        with open(fp + \".tmp\", \"wb\") as f:\n",
    "            f.write(dat)\n",
    "        \n",
    "        os.rename(fp+\".tmp\", fp)\n",
    "    \n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mnist(url1=\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\", url2=\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\", url3=\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\", url4=\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\"):\n",
    "    # from geohot\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    def parse(dat): return np.frombuffer(\n",
    "        gzip.decompress(dat), dtype=np.uint8).copy()\n",
    "\n",
    "    X_train = parse(fetch(url1))[0x10:].reshape((-1, 28, 28))\n",
    "    Y_train = parse(fetch(url2))[8:]\n",
    "    X_test = parse(fetch(url3))[0x10:].reshape((-1, 28, 28))\n",
    "    Y_test = parse(fetch(url4))[8:]\n",
    "    return X_train, Y_train, X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test = mnist()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "# inits\n",
    "def kaiming_uniform(h,w):\n",
    "    return np.random.uniform(-1.,1.,size=(h,w))/np.sqrt(2/(h*w))\n",
    "\n",
    "def kaiming_normal(h,w):\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Linear:\n",
    "    def __init__(self,h,w,init_fn = kaiming_uniform):\n",
    "        self.weight = init_fn(h,w)\n",
    "        self.grad = np.zeros((h,w))\n",
    "        self.fpass = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = x @ self.weight\n",
    "        self.fpass = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self,bpass):\n",
    "        self.grad = (self.fpass.T) @ bpass\n",
    "        bpass = bpass @ (self.weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 193.36769103,   -0.78981443,  -77.92671738, -137.43862884,\n",
       "          -6.53572108]),\n",
       " (784, 128),\n",
       " (1, 128))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = Linear(784,128)\n",
    "one.weight[0,:5], one.weight.shape, one.forward(x_train[0:1].reshape(1,-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 128), (784, 128))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one.fpass.shape, one.grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def MSELoss(yhat,y):\n",
    "    val = np.square(yhat - y).mean(axis=0)\n",
    "    grad = 2 * (yhat - y) / len(yhat)\n",
    "    return val, grad\n",
    "\n",
    "def mse(yhat, y, num_class=10, supervised=True):\n",
    "    \"\"\"read num_class when supervised\"\"\"\n",
    "    if supervised:\n",
    "        label = np.zeros((len(y), num_class), dtype=np.float32)\n",
    "        label[range(label.shape[0]), y] = 1\n",
    "        y = label\n",
    "    loss = np.square(np.subtract(yhat, y))  # vector form\n",
    "    diff = 2*np.subtract(yhat, y)/(y.shape[-1])\n",
    "    return loss, diff\n",
    "\n",
    "def CELoss(yhat,y):\n",
    "    \"\"\" cross entropy loss\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3.]), array([1.5, 3.5]), array([1.5, 3.5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "a.mean(axis=0), a.mean(axis=1), a.mean(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def SGD(lr = 1e-3, model = None):\n",
    "    for layer in model:\n",
    "        layer.weight -= lr * layer.grad\n",
    "\n",
    "def Adam():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Sequential model class ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Sequential:\n",
    "    # learn **kwargs\n",
    "    def __init__(self,layers,lossfn,opt_fn):\n",
    "        if not isinstance(layers,list):\n",
    "            self.model = [layers]\n",
    "        else:\n",
    "            self.model = layers\n",
    "        \n",
    "        self.lossfn = lossfn\n",
    "        self.opt_fn = opt_fn\n",
    "    \n",
    "    # check arguments when it comes to validation\n",
    "    def forward(self,x):\n",
    "        out = self.model[0].forward(x)\n",
    "        for layer in self.model[1:]:\n",
    "            out = layer.forward(out)\n",
    "        return out\n",
    "\n",
    "    def backward(self,grad):\n",
    "        for layer in reversed(self.model):\n",
    "            # check if grad = grad @ (weight.T) works\n",
    "            layer.backward(grad)\n",
    "            grad = grad @ (layer.weight.T)\n",
    "\n",
    "    def fit(self,x,y,epoch=1,batch_size=64,x_test=None,y_test=None):\n",
    "        # loop thru len//bs\n",
    "        losses = []\n",
    "        ln = len(x)\n",
    "        for _ in range(epoch*ln//batch_size):\n",
    "            idx = np.random.randint(0,ln,size=batch_size)\n",
    "            x_ = x[idx].reshape((-1,28*28))\n",
    "            y_ = y[idx].reshape((y[idx].shape[0],1))\n",
    "            out = self.forward(x_)\n",
    "\n",
    "            loss, grad = self.lossfn(out,y_)\n",
    "\n",
    "            self.backward(grad)\n",
    "\n",
    "            self.opt_fn(lr=1e-7, model=self.model)\n",
    "\n",
    "            losses.append(loss.mean())\n",
    "        \n",
    "        return losses\n",
    "\n",
    "    def fit_one_batch(self,x,y,epoch=1,batch_size=64,x_test=None,y_test=None):\n",
    "        # loop thru len//bs\n",
    "        losses = []\n",
    "        ln = len(x)\n",
    "        for _ in range(epoch):\n",
    "            idx = np.random.randint(0,ln,size=batch_size)\n",
    "            x_ = x[idx].reshape((-1,28*28))\n",
    "            y_ = y[idx]#.reshape((y[idx].shape[0],1))\n",
    "            out = self.forward(x_)\n",
    "            #print(np.argmax(x_),y_)\n",
    "\n",
    "            # gradient blows up\n",
    "            loss, grad = self.lossfn(y_,out)\n",
    "\n",
    "            self.backward(grad)\n",
    "\n",
    "            self.opt_fn(lr=1e-8, model=self.model)\n",
    "\n",
    "            losses.append(loss.mean())\n",
    "        \n",
    "        return losses        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-ab8b5fbcffaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-102-04e57c8c33fc>\u001b[0m in \u001b[0;36mfit_one_batch\u001b[1;34m(self, x, y, epoch, batch_size, x_test, y_test)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;31m# gradient blows up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlossfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-101-4f34301c9eb6>\u001b[0m in \u001b[0;36mmse\u001b[1;34m(yhat, y, num_class, supervised)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msupervised\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# vector form\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "# train for a epoch here\n",
    "model = Sequential([Linear(784,128),Linear(128,10)],mse,SGD)\n",
    "\n",
    "losses = model.fit_one_batch(x_train,y_train,epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(list(range(len(losses)))[:3],losses[:3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [Linear(784,128), Linear(128,10)]\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebuild everything from a lower level\n",
    "#### e.g. a tensor for layers to inherit from that handles backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_oval_clean.ipynb.\n",
      "Converted 02_NN.ipynb.\n",
      "Converted 03_NN_numpy.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
