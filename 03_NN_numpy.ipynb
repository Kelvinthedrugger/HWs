{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp nnsig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network using numpy\n",
    "#### works on cpu only if there's no pyopencl and else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# define plotting functions for productivity, wouldn't you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fetch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fetch(url):\n",
    "    import requests, hashlib, os, tempfile\n",
    "    fp = os.path.join(tempfile.gettempdir(), hashlib.md5(url.encode('utf-8')).hexdigest())\n",
    "\n",
    "    if os.path.isfile(fp):\n",
    "        with open(fp, \"rb\") as f:\n",
    "            dat = f.read()\n",
    "    \n",
    "    else:\n",
    "        dat = requests.get(url).content\n",
    "        with open(fp + \".tmp\", \"wb\") as f:\n",
    "            f.write(dat)\n",
    "        \n",
    "        os.rename(fp+\".tmp\", fp)\n",
    "    \n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mnist(url1=\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\", url2=\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\", url3=\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\", url4=\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\"):\n",
    "    # from geohot\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    def parse(dat): return np.frombuffer(\n",
    "        gzip.decompress(dat), dtype=np.uint8).copy()\n",
    "\n",
    "    X_train = parse(fetch(url1))[0x10:].reshape((-1, 28, 28))\n",
    "    Y_train = parse(fetch(url2))[8:]\n",
    "    X_test = parse(fetch(url3))[0x10:].reshape((-1, 28, 28))\n",
    "    Y_test = parse(fetch(url4))[8:]\n",
    "    return X_train, Y_train, X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test = mnist()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should set type to float32 / 16 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "# inits\n",
    "# add \"t\" dimension for convolution, not tested\n",
    "def kaiming_uniform(h,w,t=None):\n",
    "    if t is None:\n",
    "        return np.random.uniform(-1.,1.,size=(h,w))/np.sqrt(h*w)\n",
    "    else:\n",
    "        return np.random.uniform(-1.,1.,size=(h,w,t))/np.sqrt(h*w)\n",
    "\n",
    "# ref to pytorch to see how gain is calculated\n",
    "# not tested\n",
    "def kaiming_normal(h,w,gain=1):\n",
    "    return np.random.randn(h,w)/np.sqrt(2./h)*gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.21228465,  0.24765315, -0.25268094],\n",
       "        [-0.23144798, -0.04920292,  0.17055164]],\n",
       "\n",
       "       [[-0.13963562, -0.2088165 ,  0.37593109],\n",
       "        [ 0.38059491,  0.26098882,  0.02037893]],\n",
       "\n",
       "       [[-0.03300621,  0.11673715, -0.06747579],\n",
       "        [ 0.37649997,  0.3338308 , -0.01365257]],\n",
       "\n",
       "       [[ 0.09447013, -0.03462322, -0.23229127],\n",
       "        [ 0.40166175, -0.15867257,  0.31534735]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaiming_uniform(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3.]), array([1.5, 3.5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "x.mean(axis=0), x.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def stat(x):\n",
    "    \"\"\" get standard deviation and mean of matrix x\"\"\"\n",
    "    avg = x.mean()\n",
    "    std = np.square(x - avg).mean()\n",
    "    return avg, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5, 1.25)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1, 2],\n",
       "         [3, 4]]]),\n",
       " array([[1, 2],\n",
       "        [3, 4]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[None], x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if std of init weight = 1 ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to add __ repr __ and dict \n",
    "#### To store the layers and therefore more customizable, also, enable to save the weights much more convenient\n",
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Linear:\n",
    "    def __init__(self,h,w,init_fn = kaiming_uniform):\n",
    "        self.weight = init_fn(h,w)\n",
    "        self.grad = np.zeros((h,w))\n",
    "        self.fpass = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = x @ self.weight\n",
    "        self.fpass = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self,bpass):\n",
    "        self.grad = (self.fpass.T) @ bpass\n",
    "        # without returning it, it doesn't work\n",
    "        # bpass = bpass @ (self.weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00153528,  0.00014511,  0.00023883, -0.00245906, -0.00111359]),\n",
       " (784, 128),\n",
       " (1, 128))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = Linear(784,128)\n",
    "one.weight[0,:5], one.weight.shape, one.forward(x_train[0:1].reshape(1,-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 784), (784, 128))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one.fpass.shape, one.grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def MSELoss(yhat,y,num_class=10,supervised=True):\n",
    "    if supervised:\n",
    "        label = np.zeros((len(y), num_class), dtype=np.float32)\n",
    "        label[range(label.shape[0]), y] = 1\n",
    "        y = label\n",
    "    val = np.square(yhat - y).mean(axis=0)\n",
    "    grad = 2 * (yhat - y) / len(yhat)\n",
    "    return val, grad\n",
    "\n",
    "# can be achieved via NNL_Loss and softmax\n",
    "def NNL():\n",
    "    \"\"\" negative log likelihood \"\"\"\n",
    "    return\n",
    "\n",
    "def CELoss(yhat,y):\n",
    "    \"\"\" cross entropy loss\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3.]), array([1.5, 3.5]), array([1.5, 3.5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "a.mean(axis=0), a.mean(axis=1), a.mean(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def SGD(lr = 1e-3, model = None):\n",
    "    for layer in model:\n",
    "        layer.weight -= lr * layer.grad\n",
    "\n",
    "def Adam():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Sequential model class ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Sequential:\n",
    "    # learn **kwargs\n",
    "    def __init__(self,layers,lossfn,opt_fn):\n",
    "        if not isinstance(layers,list):\n",
    "            self.model = [layers]\n",
    "        else:\n",
    "            self.model = layers\n",
    "        \n",
    "        self.lossfn = lossfn\n",
    "        self.opt_fn = opt_fn\n",
    "    \n",
    "    # check arguments when it comes to validation\n",
    "    def forward(self,x):\n",
    "        out = self.model[0].forward(x)\n",
    "        for layer in self.model[1:]:\n",
    "            out = layer.forward(out)\n",
    "        return out\n",
    "\n",
    "    def backward(self,grad):\n",
    "        for layer in reversed(self.model):\n",
    "            layer.backward(grad)\n",
    "            grad = grad @ (layer.weight.T)\n",
    "\n",
    "    def fit(self,x,y,epoch=1,batch_size=64,x_test=None,y_test=None):\n",
    "        # loop thru len//bs\n",
    "        losses = []\n",
    "        ln = len(x)\n",
    "        for _ in range(ln//batch_size):\n",
    "            losses += self.fit_one_batch(x,y,epoch,batch_size,x_test,y_test)\n",
    "        return losses\n",
    "\n",
    "    def fit_one_batch(self,x,y,epoch=1,batch_size=64,x_test=None,y_test=None):\n",
    "        # loop thru len//bs\n",
    "        losses = []\n",
    "        ln = len(x)\n",
    "        for _ in range(epoch):\n",
    "            idx = np.random.randint(0,ln,size=batch_size)\n",
    "            x_ = x[idx].reshape((-1,28*28))\n",
    "            y_ = y[idx]\n",
    "            out = self.forward(x_)\n",
    "\n",
    "            loss, grad = self.lossfn(out,y_)\n",
    "            self.backward(grad)\n",
    "            self.opt_fn(lr=1e-5, model=self.model)\n",
    "\n",
    "            losses.append(loss.mean())\n",
    "        \n",
    "        return losses        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for a epoch here\n",
    "model = Sequential([Linear(784,128),Linear(128,10)],MSELoss,SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = model.fit(x_train,y_train,epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.04187458886272651"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(list(range(len(losses))),losses)\n",
    "plt.show()\n",
    "losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n",
      "2 2\n",
      "1 1\n",
      "0 0\n",
      "4 4\n",
      "1 1\n",
      "4 4\n",
      "9 9\n",
      "5 5\n",
      "9 9\n"
     ]
    }
   ],
   "source": [
    "\"\"\" It's correct now \"\"\"\n",
    "for i in range(10):\n",
    "    print(np.argmax(model.forward(x_test[i:i+1].reshape((-1,28*28)))), y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.8298\n"
     ]
    }
   ],
   "source": [
    "# add accuracy first\n",
    "# test passed, can add to model class\n",
    "acc = 0\n",
    "bs = 256\n",
    "\n",
    "for i in range(0,x_test.shape[0],bs):\n",
    "    acc += int((np.argmax(model.forward(x_test[i:i+bs].reshape((-1,28*28))),axis=-1) == y_test[i:i+bs]).sum())\n",
    "\n",
    "\n",
    "print(\"accuracy is: %.4f\" % (acc/(x_test.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape: following NHWC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check docs to see if there's is a different way to calculated gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# not tested\n",
    "class Conv:\n",
    "    def __init__(self,filters,kernelsize,padding=0,init_fn=kaiming_uniform):\n",
    "        self.weight = np.zeros((kernelsize,kernelsize,filters))\n",
    "        for f in self.weight:\n",
    "            f = init_fn(kernelsize,kernelsize)\n",
    "        self.grad = np.zeros((kernelsize,kernelsize,filter))\n",
    "        self.fpass = None\n",
    "\n",
    "    def forward(self,x):\n",
    "        # take advantage of einsum for speed and simplicity\n",
    "        # assume x.shape[0] == x.shape[1]\n",
    "        # ...\n",
    "        return\n",
    "\n",
    "    def backward(self,grad):\n",
    "        # transpose weight to calculate gradient ?\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(28-3)//2+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# naive function of convolution\n",
    "def naive(f,x,st=2,ks=3):\n",
    "    out = np.zeros((((x.shape[0]-ks)//st+1),((x.shape[1]-ks)//st+1)))\n",
    "    for i in range(0,x.shape[0]-1,st):\n",
    "        for j in range(0,x.shape[1]-1,st):\n",
    "            # for debug\n",
    "            # print(i,\":\",i+ks,\"->\",j,\":\",j+ks)\n",
    "            # print(x[i:i+ks,j:j+ks])\n",
    "            print(f.shape,x[i:i+ks,j:j+ks].shape)\n",
    "            out[i//st,j//st] = np.multiply(f,x[i:i+ks,j:j+ks]).sum()\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 420.,  492.,  564.],\n",
       "       [ 924.,  996., 1068.],\n",
       "       [1428., 1500., 1572.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive(np.arange(9).reshape(3,3),np.arange(49).reshape(7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv_dump\n",
    "#### written for debugging & testing of Conv class\n",
    "#### TODO:\n",
    "####  \n",
    "####  Adjust the inner/outer loop of forward() (actual ConvOps per se) -> loop thru the input only once (filter-first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for not moving up and down\n",
    "import numpy as np\n",
    "from HWS.nnsig import kaiming_normal\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# can be used to test Conv class\n",
    "# add Conv in naive way\n",
    "class Conv_dump:\n",
    "    def __init__(self,filters=1,kernelsize=3,stride=2,padding=0,init_fn=kaiming_uniform):\n",
    "        self.f = init_fn(kernelsize,kernelsize,filters)\n",
    "        self.grad = np.zeros((kernelsize,kernelsize,filters))\n",
    "        self.fpass = None\n",
    "        self.ks = kernelsize\n",
    "        self.st = stride\n",
    "\n",
    "    def forward(self,x):\n",
    "        # pre cache, don't know if it's actually faster compare to refering to self.sth every time\n",
    "        f = self.f\n",
    "        ks = self.ks\n",
    "        st = self.st\n",
    "\n",
    "        out = np.zeros((((x.shape[0]-ks)//st+1),((x.shape[1]-ks)//st+1),f.shape[-1]))\n",
    "\n",
    "        \"\"\" \n",
    "        About the loop: should try to reduce the time of walking thru input feature\n",
    "        now: loop filters{loop thru input} ## SLOW\n",
    "        faster version will be to loop thru every filter at the inner-est loop, then loop thru input\n",
    "         , which will give us #walking thru = 1\n",
    "        \"\"\"\n",
    "        ## DEBUG\n",
    "        # now, it's slow\n",
    "        for k in range(f.shape[-1]):\n",
    "            out[:,:,k] = naive(f[:,:,k],x)\n",
    "\n",
    "        self.fpass = x\n",
    "        return out\n",
    "\n",
    "    def backward(self,grad):\n",
    "        # transpose weight to calculate gradient ?\n",
    "        # loop\n",
    "        #   x = input[i:i+ks,j:j+ks] # rth ks*ks matrix\n",
    "        #   y = rth element in grad\n",
    "        #   grad_per_step = x*y\n",
    "        # convops\n",
    "        # return it\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 27, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.random.uniform(-1.,1.,size=(27,27,1))\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13, 13, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = Conv_dump()\n",
    "l.forward(b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2810f0a5408>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(l.forward(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m \u001b[0mnaive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[1;31mSource:\u001b[0m   \n",
      "\u001b[1;32mdef\u001b[0m \u001b[0mnaive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# for debug\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# print(i,\":\",i+ks,\"->\",j,\":\",j+ks)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[1;31m# print(x[i:i+ks,j:j+ks])\u001b[0m\u001b[1;33m\n",
      "\u001b[0m            \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\kelvin\\documents\\github\\hws\\<ipython-input-2-e8186fba8073>\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "naive??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 3, 1)\n",
      "(3, 3) (3, 2, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,3) (3,2,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-63100f557454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-c13b3c1639e3>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# now, it's slow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnaive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfpass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-3bedfd5a001e>\u001b[0m in \u001b[0;36mnaive\u001b[1;34m(f, x, st, ks)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;31m# print(x[i:i+ks,j:j+ks])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,3) (3,2,1) "
     ]
    }
   ],
   "source": [
    "c = np.random.uniform(-1.,1.,size=(28,28,1))\n",
    "plt.imshow(l.forward(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten / unsqueeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I don't think this is the right way to do, since it requires way too much conditioning in the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# not tested: 90% certain it's correct\n",
    "# we're only use library (numpy) \n",
    "# since it's slow to do computation in pure python\n",
    "class Flatten:\n",
    "    \"\"\"\n",
    "    reshape input to target shape\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.shape=None\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\" \n",
    "        Should consider batch size\n",
    "        image: (h,w,c) -> (b,h,w,c)\n",
    "         flatten: (b,h*w*c)\n",
    "        \n",
    "        otherwise: \n",
    "        (b,d) -> (1, b*d)\n",
    "\n",
    "        \"\"\"\n",
    "        self.shape = x.shape\n",
    "        return x.reshape((1,-1))\n",
    "    \n",
    "    def backward(self,grad):\n",
    "        return grad.reshape(self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2],\n",
       "        [3, 4]]),\n",
       " array([[1, 2, 3, 4]]),\n",
       " array([[1, 2],\n",
       "        [3, 4]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "l = Flatten()\n",
    "x, l.forward(x), l.backward(l.forward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN here (regular one and pure Conv one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'filters' and 'kernelsize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-fcc89bbddb86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnn_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'filters' and 'kernelsize'"
     ]
    }
   ],
   "source": [
    "cnn_reg = Sequential([Conv(), Conv(), Flatten(), Linear(), Linear()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_p = Sequential([Conv(), Conv(), Linear()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor class to inherit from\n",
    "# implement context tensor ??\n",
    "class Tensor:\n",
    "    def __init__(self):\n",
    "        self.grad = None\n",
    "    \n",
    "    def unsqueeze():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebuild everything from a lower level\n",
    "#### e.g. a tensor for layers to inherit from that handles backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_oval_clean.ipynb.\n",
      "Converted 02_NN.ipynb.\n",
      "Converted 03_NN_numpy.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
