{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp nnsig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network using numpy\n",
    "#### works on cpu only if there's no pyopencl and else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fetch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fetch(url):\n",
    "    import requests, hashlib, os, tempfile\n",
    "    fp = os.path.join(tempfile.gettempdir(), hashlib.md5(url.encode('utf-8')).hexdigest())\n",
    "\n",
    "    if os.path.isfile(fp):\n",
    "        with open(fp, \"rb\") as f:\n",
    "            dat = f.read()\n",
    "    \n",
    "    else:\n",
    "        dat = requests.get(url).content\n",
    "        with open(fp + \".tmp\", \"wb\") as f:\n",
    "            f.write(dat)\n",
    "        \n",
    "        os.rename(fp+\".tmp\", fp)\n",
    "    \n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mnist(url1=\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\", url2=\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\", url3=\"http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\", url4=\"http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\"):\n",
    "    # from geohot\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    def parse(dat): return np.frombuffer(\n",
    "        gzip.decompress(dat), dtype=np.uint8).copy()\n",
    "\n",
    "    X_train = parse(fetch(url1))[0x10:].reshape((-1, 28, 28))\n",
    "    Y_train = parse(fetch(url2))[8:]\n",
    "    X_test = parse(fetch(url3))[0x10:].reshape((-1, 28, 28))\n",
    "    Y_test = parse(fetch(url4))[8:]\n",
    "    return X_train, Y_train, X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test = mnist()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should set type to float32 / 16 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "# inits\n",
    "# add \"t\" dimension for convolution, not tested\n",
    "def kaiming_uniform(h,w,t=None):\n",
    "    if t is None:\n",
    "        return np.random.uniform(-1.,1.,size=(h,w))/np.sqrt(h*w)\n",
    "    else:\n",
    "        return np.random.uniform(-1.,1.,size=(t,h,w))/np.sqrt(h*w)\n",
    "\n",
    "# ref to pytorch to see how gain is calculated\n",
    "# not tested\n",
    "def kaiming_normal(h,w,gain=1):\n",
    "    return np.random.randn(h,w)/np.sqrt(2./h)*gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.05148971, -0.24720447,  0.10005553],\n",
       "        [ 0.14303334, -0.18515969,  0.10291871]],\n",
       "\n",
       "       [[-0.04300571,  0.2031914 ,  0.20765575],\n",
       "        [-0.01336821, -0.34945044, -0.04187129]],\n",
       "\n",
       "       [[ 0.30659053,  0.35966141,  0.34803073],\n",
       "        [-0.21486072,  0.30869637,  0.22982583]],\n",
       "\n",
       "       [[ 0.14296303, -0.0885754 ,  0.05013159],\n",
       "        [ 0.39251967, -0.39095989,  0.08196173]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaiming_uniform(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3.]), array([1.5, 3.5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "x.mean(axis=0), x.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def stat(x):\n",
    "    \"\"\" get standard deviation and mean of matrix x\"\"\"\n",
    "    avg = x.mean()\n",
    "    std = np.square(x - avg).mean()\n",
    "    return avg, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.5, 1.25)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1, 2],\n",
       "         [3, 4]]]),\n",
       " array([[1, 2],\n",
       "        [3, 4]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[None], x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if std of init weight = 1 ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to add __ repr __ and dict \n",
    "#### To store the layers and therefore more customizable, also, enable to save the weights much more convenient\n",
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Linear:\n",
    "    def __init__(self,h,w,init_fn = kaiming_uniform):\n",
    "        self.weight = init_fn(h,w)\n",
    "        self.grad = np.zeros((h,w))\n",
    "        self.fpass = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = x @ self.weight\n",
    "        self.fpass = x\n",
    "        return out\n",
    "    \n",
    "    def backward(self,bpass):\n",
    "        self.grad = (self.fpass.T) @ bpass\n",
    "        # without returning it, it doesn't work\n",
    "        # bpass = bpass @ (self.weight.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00143969,  0.00041254, -0.00234367,  0.00168925, -0.00220665]),\n",
       " (784, 128),\n",
       " (1, 128))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = Linear(784,128)\n",
    "one.weight[0,:5], one.weight.shape, one.forward(x_train[0:1].reshape(1,-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 784), (784, 128))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one.fpass.shape, one.grad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def MSELoss(yhat,y,num_class=10,supervised=True):\n",
    "    if supervised:\n",
    "        label = np.zeros((len(y), num_class), dtype=np.float32)\n",
    "        label[range(label.shape[0]), y] = 1\n",
    "        y = label\n",
    "    val = np.square(yhat - y).mean(axis=0)\n",
    "    grad = 2 * (yhat - y) / len(yhat)\n",
    "    return val, grad\n",
    "\n",
    "# can be achieved via NNL_Loss and softmax\n",
    "def NNL():\n",
    "    \"\"\" negative log likelihood \"\"\"\n",
    "    return\n",
    "\n",
    "def CELoss(yhat,y):\n",
    "    \"\"\" cross entropy loss\"\"\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3.]), array([1.5, 3.5]), array([1.5, 3.5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "a.mean(axis=0), a.mean(axis=1), a.mean(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def SGD(lr = 1e-3, model = None):\n",
    "    for layer in model:\n",
    "        layer.weight -= lr * layer.grad\n",
    "\n",
    "def Adam():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Sequential model class ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Sequential:\n",
    "    # learn **kwargs\n",
    "    def __init__(self,layers,lossfn,opt_fn):\n",
    "        if not isinstance(layers,list):\n",
    "            self.model = [layers]\n",
    "        else:\n",
    "            self.model = layers\n",
    "        \n",
    "        self.lossfn = lossfn\n",
    "        self.opt_fn = opt_fn\n",
    "    \n",
    "    # check arguments when it comes to validation\n",
    "    def forward(self,x):\n",
    "        out = self.model[0].forward(x)\n",
    "        for layer in self.model[1:]:\n",
    "            out = layer.forward(out)\n",
    "        return out\n",
    "\n",
    "    def backward(self,grad):\n",
    "        for layer in reversed(self.model):\n",
    "            layer.backward(grad)\n",
    "            grad = grad @ (layer.weight.T)\n",
    "\n",
    "    def fit(self,x,y,epoch=1,batch_size=64,x_test=None,y_test=None):\n",
    "        # loop thru len//bs\n",
    "        losses = []\n",
    "        ln = len(x)\n",
    "        for _ in range(ln//batch_size):\n",
    "            losses += self.fit_one_batch(x,y,epoch,batch_size,x_test,y_test)\n",
    "        return losses\n",
    "\n",
    "    def fit_one_batch(self,x,y,epoch=1,batch_size=64,x_test=None,y_test=None):\n",
    "        # loop thru len//bs\n",
    "        losses = []\n",
    "        ln = len(x)\n",
    "        for _ in range(epoch):\n",
    "            idx = np.random.randint(0,ln,size=batch_size)\n",
    "            x_ = x[idx].reshape((-1,28*28))\n",
    "            y_ = y[idx]\n",
    "            out = self.forward(x_)\n",
    "\n",
    "            loss, grad = self.lossfn(out,y_)\n",
    "            self.backward(grad)\n",
    "            self.opt_fn(lr=1e-5, model=self.model)\n",
    "\n",
    "            losses.append(loss.mean())\n",
    "        \n",
    "        return losses        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for a epoch here\n",
    "model = Sequential([Linear(784,128),Linear(128,10)],MSELoss,SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = model.fit(x_train,y_train,epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.04918957495571788"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(list(range(len(losses))),losses)\n",
    "plt.show()\n",
    "losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 7\n",
      "2 2\n",
      "1 1\n",
      "0 0\n",
      "4 4\n",
      "1 1\n",
      "4 4\n",
      "9 9\n",
      "5 5\n",
      "9 9\n"
     ]
    }
   ],
   "source": [
    "\"\"\" It's correct now \"\"\"\n",
    "for i in range(10):\n",
    "    print(np.argmax(model.forward(x_test[i:i+1].reshape((-1,28*28)))), y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.8346\n"
     ]
    }
   ],
   "source": [
    "# add accuracy first\n",
    "# test passed, can add to model class\n",
    "acc = 0\n",
    "bs = 256\n",
    "\n",
    "for i in range(0,x_test.shape[0],bs):\n",
    "    acc += int((np.argmax(model.forward(x_test[i:i+bs].reshape((-1,28*28))),axis=-1) == y_test[i:i+bs]).sum())\n",
    "\n",
    "\n",
    "print(\"accuracy is: %.4f\" % (acc/(x_test.shape[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check docs to see if there's is a different way to calculated gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# not tested\n",
    "class Conv:\n",
    "    def __init__(self,filters,kernelsize,padding=0,init_fn=kaiming_uniform):\n",
    "        # weight: wrong shape \n",
    "        self.weight = np.zeros((filters,kernelsize,kernelsize))\n",
    "        for f in self.weight:\n",
    "            f = init_fn(kernelsize,kernelsize)\n",
    "        self.grad = np.zeros((filters,kernelsize,kernelsize))\n",
    "        self.fpass = None\n",
    "\n",
    "    def forward(self,x):\n",
    "        # take advantage of einsum for speed and simplicity\n",
    "        # assume x.shape[0] == x.shape[1]\n",
    "        # ...\n",
    "        return\n",
    "\n",
    "    def backward(self,grad):\n",
    "        # transpose weight to calculate gradient ?\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive function of convolution\n",
    "def naive(f,x,st=2,ks=3):\n",
    "    out = np.zeros((((x.shape[0]-ks)//st+1),((x.shape[1]-ks)//st+1)))\n",
    "    for i in range(0,x.shape[0]-1,st):\n",
    "        for j in range(0,x.shape[1]-1,st):\n",
    "            # for debug\n",
    "            # print(i,\":\",i+ks,\"->\",j,\":\",j+ks)\n",
    "            # print(x[i:i+ks,j:j+ks])\n",
    "            out[i//st,j//st] = np.multiply(f,x[i:i+ks,j:j+ks]).sum()\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 420.,  492.,  564.],\n",
       "       [ 924.,  996., 1068.],\n",
       "       [1428., 1500., 1572.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive(f,np.arange(49).reshape(7,7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Conv in naive way\n",
    "class Conv_dump:\n",
    "    def __init__(self,filters,kernelsize,padding=0,init_fn=kaiming_uniform):\n",
    "        self.f = init_fn(kernelsize,kernelsize,filters)\n",
    "        self.grad = np.zeros((kernelsize,kernelsize,filters))\n",
    "        self.fpass = None\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = np.zeros((((x.shape[0]-ks)//st+1),((x.shape[1]-ks)//st+1)),self.f.shape[-1])\n",
    "        for k in range(self.f.shape[-1]):\n",
    "            for i in range(0,x.shape[0]-1,st):\n",
    "                for j in range(0,x.shape[1]-1,st):\n",
    "                    out[i//st,j//st,k] = np.multiply(self.f[:,:,k],x[i:i+ks,j:j+ks]).sum()\n",
    "            \n",
    "        return out\n",
    "\n",
    "    def backward(self,grad):\n",
    "        # transpose weight to calculate gradient ?\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten / unsqueeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I don't think this is the right way to do, since it requires way too much conditioning in the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# not tested: 90% certain it's correct\n",
    "# we're only use library (numpy) \n",
    "# since it's slow to do computation in pure python\n",
    "class Flatten:\n",
    "    \"\"\"\n",
    "    reshape input to target shape\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.shape=None\n",
    "\n",
    "    def forward(self,x):\n",
    "        self.shape = x.shape\n",
    "        return x.reshape((1,-1))\n",
    "    \n",
    "    def backward(self,grad):\n",
    "        return grad.reshape(self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2],\n",
       "        [3, 4]]),\n",
       " array([[1, 2, 3, 4]]),\n",
       " array([[1, 2],\n",
       "        [3, 4]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "l = Flatten()\n",
    "x, l.forward(x), l.backward(l.forward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN here (regular one and pure Conv one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'filters' and 'kernelsize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-fcc89bbddb86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnn_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'filters' and 'kernelsize'"
     ]
    }
   ],
   "source": [
    "cnn_reg = Sequential([Conv(), Conv(), Flatten(), Linear(), Linear()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_p = Sequential([Conv(), Conv(), Linear()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor class to inherit from\n",
    "# implement context tensor ??\n",
    "class Tensor:\n",
    "    def __init__(self):\n",
    "        self.grad = None\n",
    "    \n",
    "    def unsqueeze():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebuild everything from a lower level\n",
    "#### e.g. a tensor for layers to inherit from that handles backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_oval_clean.ipynb.\n",
      "Converted 02_NN.ipynb.\n",
      "Converted 03_NN_numpy.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
